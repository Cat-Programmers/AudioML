{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavfile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import whisper\n",
    "\n",
    "model_name = 'large'\n",
    "model_whisper = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('augmented_dataset.csv', sep=';', names=['Correct', 'Dialogue'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тестовые и тренировочные данные\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Токенизация и векторизация текста\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Dialogue'])\n",
    "y_train = train_df['Correct']\n",
    "X_test = vectorizer.transform(test_df['Dialogue'])\n",
    "y_test = test_df['Correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы для работы с аудиофайлами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь для сохранения временного аудиофайла\n",
    "AUDIO_FOLDER = 'temp_audio'\n",
    "if not os.path.exists(AUDIO_FOLDER):\n",
    "    os.makedirs(AUDIO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file):\n",
    "    result = model_whisper.transcribe(audio_file)\n",
    "    cleaned_text = result[\"text\"].replace(\"Продолжение следует...\", \"\")\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(input_file):\n",
    "    base_name, ext = os.path.splitext(input_file)\n",
    "    if ext != '.wav':\n",
    "        output_file = os.path.join(AUDIO_FOLDER, base_name + '.wav')\n",
    "        data, samplerate = sf.read(input_file)\n",
    "        sf.write(output_file, data, samplerate)\n",
    "        return output_file\n",
    "    else:\n",
    "        return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_path):\n",
    "    base_name, ext = os.path.splitext(audio_path)\n",
    "    output_path = base_name + '.wav'\n",
    "\n",
    "    sr, y = wavfile.read(audio_path)\n",
    "    y = y.astype(np.float32) / 32767\n",
    "\n",
    "    # Параметры анализа\n",
    "    win_len_sec = 0.02  # Длина окна в секундах\n",
    "    hop_frac = 0.5      # Доля перекрытия окон\n",
    "    win_len = int(win_len_sec * sr)\n",
    "    hop_size = int(win_len * hop_frac)\n",
    "\n",
    "    # Определение участка шума\n",
    "    window_length = 2048\n",
    "    hop_length = 512\n",
    "    rms = librosa.feature.rms(y=y, frame_length=window_length, hop_length=hop_length)\n",
    "    rms_threshold = np.percentile(rms, 10)  # Используем 10-й перцентиль для определения шума\n",
    "    noise_indices = np.where(rms[0] < rms_threshold)[0]\n",
    "\n",
    "    # Извлечение шума\n",
    "    noise_start = noise_indices[0] * hop_length\n",
    "    noise_end = (noise_indices[-1] + 1) * hop_length\n",
    "    noise = y[noise_start:noise_end]\n",
    "\n",
    "    # Вычисление спектрограммы\n",
    "    S_full, phase = librosa.magphase(librosa.stft(y))\n",
    "\n",
    "    # Определение среднего шума по частотам\n",
    "    noise_stft = librosa.stft(noise)\n",
    "    noise_mag = np.abs(noise_stft)\n",
    "    mean_noise_mag = np.mean(noise_mag, axis=1, keepdims=True)\n",
    "\n",
    "    # Удаление шума (метод спектрального вычитания)\n",
    "    S_denoised = S_full - mean_noise_mag\n",
    "    S_denoised = np.maximum(S_denoised, 0)  # Убираем отрицательные значения\n",
    "\n",
    "    # Обратное преобразование в звуковой сигнал\n",
    "    clean_signal = librosa.istft(S_denoised * phase)\n",
    "\n",
    "    # Нормализация и сохранение нового аудиофайла\n",
    "    clean_signal = np.int16(clean_signal / np.max(np.abs(clean_signal)) * 32767)\n",
    "\n",
    "    # Сохранение очищенного аудиофайла\n",
    "    sf.write(output_path, clean_signal, sr)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_amplification(audio_path):\n",
    "    base_name, ext = os.path.splitext(audio_path)\n",
    "    output_path = base_name + '.wav'\n",
    "    \n",
    "    sr, y = wavfile.read(audio_path)\n",
    "    y = y.astype(np.float32) / 32767  # Нормализация сигнала\n",
    "\n",
    "    gain = 1.7\n",
    "    y_amplified = y * gain\n",
    "\n",
    "    # Обрезка значений, чтобы избежать клиппинга\n",
    "    y_amplified = np.clip(y_amplified, -1.0, 1.0)\n",
    "\n",
    "    # Обратная нормализация и сохранение аудиофайла\n",
    "    y_amplified = np.int16(y_amplified * 32767)\n",
    "\n",
    "    # Сохранение очищенного аудиофайла\n",
    "    sf.write(output_path, y_amplified, sr)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и запуск приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение пути для загрузки HTML-файла\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return send_file('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на наличие нарушения и вывод текста\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_audio():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'})\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'})\n",
    "    if file:\n",
    "        audio_file_path = convert_to_wav(file.filename)\n",
    "        denoised_audio_file_path = remove_noise(audio_file_path)\n",
    "        amplification_audio_file_path =voice_amplification(denoised_audio_file_path)\n",
    "        transcribed_text = transcribe_audio(amplification_audio_file_path)\n",
    "        new_text_vectorized = vectorizer.transform([transcribed_text])\n",
    "        prediction = model.predict(new_text_vectorized)\n",
    "        if prediction[0] == 1:\n",
    "            result = \"Нарушений не обнаружено: \" + new_text_vectorized.toarray().tolist() \n",
    "        else:\n",
    "            # Загружаем стоп-слова\n",
    "            nltk.download('stopwords')\n",
    "            stop_words = set(stopwords.words('russian'))  # Замените 'russian' на нужный вам язык\n",
    "\n",
    "            # Получаем список признаков и коэффициенты модели\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            coefs = model.coef_[0]\n",
    "\n",
    "            # Находим слова, которые имеют негативное влияние\n",
    "            negative_influence_words = [feature_names[i] for i in range(len(feature_names)) if new_text_vectorized[0, i] != 0 and coefs[i] < 0]\n",
    "\n",
    "            # Разделяем транскрибированный текст на слова\n",
    "            words = transcribed_text.split()\n",
    "\n",
    "            # Создаем новый список для выделенного текста\n",
    "            highlighted_words = []\n",
    "\n",
    "            # Проходимся по каждому слову в тексте\n",
    "            for word in words:\n",
    "                # Если слово является негативным и не является стоп-словом, выделяем его тегом <span>\n",
    "                if word in negative_influence_words and word.lower() not in stop_words:\n",
    "                    highlighted_words.append(f\"<span class='highlight'>{word}</span>\")\n",
    "                else:\n",
    "                    highlighted_words.append(word)\n",
    "\n",
    "            # Объединяем слова обратно в строку\n",
    "            highlighted_text = ' '.join(highlighted_words)\n",
    "\n",
    "            result = \"Имеется нарушение: \" + highlighted_text\n",
    "        return jsonify({'result': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск сервера на локальном хосте\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
