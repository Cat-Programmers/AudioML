{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m     17\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 18\u001b[0m model_whisper \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Никита\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\whisper\\__init__.py:133\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[0;32m    130\u001b[0m     download_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXDG_CACHE_HOME\u001b[39m\u001b[38;5;124m\"\u001b[39m, default), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[1;32m--> 133\u001b[0m     checkpoint_file \u001b[38;5;241m=\u001b[39m \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     alignment_heads \u001b[38;5;241m=\u001b[39m _ALIGNMENT_HEADS[name]\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(name):\n",
      "File \u001b[1;32mc:\\Users\\Никита\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\whisper\\__init__.py:61\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(url, root, in_memory)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(download_target):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(download_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 61\u001b[0m         model_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hashlib\u001b[38;5;241m.\u001b[39msha256(model_bytes)\u001b[38;5;241m.\u001b[39mhexdigest() \u001b[38;5;241m==\u001b[39m expected_sha256:\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model_bytes \u001b[38;5;28;01mif\u001b[39;00m in_memory \u001b[38;5;28;01melse\u001b[39;00m download_target\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavfile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import webbrowser\n",
    "from threading import Timer\n",
    "import whisper\n",
    "\n",
    "model_name = 'large'\n",
    "model_whisper = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('augmented_dataset.csv', sep=';', names=['Correct', 'Dialogue'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тестовые и тренировочные данные\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Токенизация и векторизация текста\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Dialogue'])\n",
    "y_train = train_df['Correct']\n",
    "X_test = vectorizer.transform(test_df['Dialogue'])\n",
    "y_test = test_df['Correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы для работы с аудиофайлами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь для сохранения временного аудиофайла\n",
    "AUDIO_FOLDER = 'temp_audio'\n",
    "if not os.path.exists(AUDIO_FOLDER):\n",
    "    os.makedirs(AUDIO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file):\n",
    "    result = model_whisper.transcribe(audio_file)\n",
    "    cleaned_text = result[\"text\"].replace(\"Продолжение следует...\", \"\")\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(input_file):\n",
    "    base_name, ext = os.path.splitext(input_file)\n",
    "    if ext != '.wav':\n",
    "        output_file = os.path.join(AUDIO_FOLDER, base_name + '.wav')\n",
    "        data, samplerate = sf.read(input_file)\n",
    "        sf.write(output_file, data, samplerate)\n",
    "        return output_file\n",
    "    else:\n",
    "        return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_path):\n",
    "    base_name, ext = os.path.splitext(audio_path)\n",
    "    output_path = base_name + '.wav'\n",
    "\n",
    "    sr, y = wavfile.read(audio_path)\n",
    "    y = y.astype(np.float32) / 32767\n",
    "\n",
    "    # Параметры анализа\n",
    "    win_len_sec = 0.02  # Длина окна в секундах\n",
    "    hop_frac = 0.5      # Доля перекрытия окон\n",
    "    win_len = int(win_len_sec * sr)\n",
    "    hop_size = int(win_len * hop_frac)\n",
    "\n",
    "    # Определение участка шума\n",
    "    window_length = 2048\n",
    "    hop_length = 512\n",
    "    rms = librosa.feature.rms(y=y, frame_length=window_length, hop_length=hop_length)\n",
    "    rms_threshold = np.percentile(rms, 10)  # Используем 10-й перцентиль для определения шума\n",
    "    noise_indices = np.where(rms[0] < rms_threshold)[0]\n",
    "\n",
    "    # Извлечение шума\n",
    "    noise_start = noise_indices[0] * hop_length\n",
    "    noise_end = (noise_indices[-1] + 1) * hop_length\n",
    "    noise = y[noise_start:noise_end]\n",
    "\n",
    "    # Вычисление спектрограммы\n",
    "    S_full, phase = librosa.magphase(librosa.stft(y))\n",
    "\n",
    "    # Определение среднего шума по частотам\n",
    "    noise_stft = librosa.stft(noise)\n",
    "    noise_mag = np.abs(noise_stft)\n",
    "    mean_noise_mag = np.mean(noise_mag, axis=1, keepdims=True)\n",
    "\n",
    "    # Удаление шума (метод спектрального вычитания)\n",
    "    S_denoised = S_full - mean_noise_mag\n",
    "    S_denoised = np.maximum(S_denoised, 0)  # Убираем отрицательные значения\n",
    "\n",
    "    # Обратное преобразование в звуковой сигнал\n",
    "    clean_signal = librosa.istft(S_denoised * phase)\n",
    "\n",
    "    # Нормализация и сохранение нового аудиофайла\n",
    "    clean_signal = np.int16(clean_signal / np.max(np.abs(clean_signal)) * 32767)\n",
    "\n",
    "    # Сохранение очищенного аудиофайла\n",
    "    sf.write(output_path, clean_signal, sr)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_amplification(audio_path):\n",
    "    base_name, ext = os.path.splitext(audio_path)\n",
    "    output_path = base_name + '.wav'\n",
    "    \n",
    "    sr, y = wavfile.read(audio_path)\n",
    "    y = y.astype(np.float32) / 32767  # Нормализация сигнала\n",
    "\n",
    "    gain = 1.7\n",
    "    y_amplified = y * gain\n",
    "\n",
    "    # Обрезка значений, чтобы избежать клиппинга\n",
    "    y_amplified = np.clip(y_amplified, -1.0, 1.0)\n",
    "\n",
    "    # Обратная нормализация и сохранение аудиофайла\n",
    "    y_amplified = np.int16(y_amplified * 32767)\n",
    "\n",
    "    # Сохранение очищенного аудиофайла\n",
    "    sf.write(output_path, y_amplified, sr)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и запуск приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение пути для загрузки HTML-файла\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return send_file('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на наличие нарушения и вывод текста\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_audio():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'})\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'})\n",
    "    if file:\n",
    "        audio_file_path = convert_to_wav(file.filename)\n",
    "        denoised_audio_file_path = remove_noise(audio_file_path)\n",
    "        amplification_audio_file_path =voice_amplification(denoised_audio_file_path)\n",
    "        transcribed_text = transcribe_audio(amplification_audio_file_path)\n",
    "        new_text_vectorized = vectorizer.transform([transcribed_text])\n",
    "        prediction = model.predict(new_text_vectorized)\n",
    "        if prediction[0] == 1:\n",
    "            result = \"Нарушений не обнаружено: \" + new_text_vectorized\n",
    "        else:\n",
    "            # Загружаем стоп-слова\n",
    "            nltk.download('stopwords')\n",
    "            stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "            # Получаем список признаков и коэффициенты модели\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            coefs = model.coef_[0]\n",
    "\n",
    "            # Находим слова, которые имеют негативное влияние\n",
    "            negative_influence_words = [feature_names[i] for i in range(len(feature_names)) if new_text_vectorized[0, i] != 0 and coefs[i] < 0]\n",
    "\n",
    "            # Разделяем транскрибированный текст на слова\n",
    "            words = transcribed_text.split()\n",
    "\n",
    "            # Создаем новый список для выделенного текста\n",
    "            highlighted_words = []\n",
    "\n",
    "            # Проходимся по каждому слову в тексте\n",
    "            for word in words:\n",
    "                if word in negative_influence_words and word.lower() not in stop_words:\n",
    "                    highlighted_words.append(f\"<span class='highlight'>{word}</span>\")\n",
    "                else:\n",
    "                    highlighted_words.append(word)\n",
    "\n",
    "            # Объединяем слова обратно в строку\n",
    "            highlighted_text = ' '.join(highlighted_words)\n",
    "\n",
    "            result = \"Имеется нарушение: \" + highlighted_text\n",
    "        return jsonify({'result': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_browser():\n",
    "    webbrowser.open_new('http://127.0.0.1:5000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск сервера на локальном хосте\n",
    "if __name__ == '__main__':\n",
    "    Timer(1, open_browser).start()\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
