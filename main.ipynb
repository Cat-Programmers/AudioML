{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, send_file, send_from_directory\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "import speech_recognition as sr\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('augmented_dataset.csv', sep=';', names=['Correct', 'Dialogue'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тестовые и тренировочные данные\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Токенизация и векторизация текста\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Dialogue'])\n",
    "y_train = train_df['Correct']\n",
    "X_test = vectorizer.transform(test_df['Dialogue'])\n",
    "y_test = test_df['Correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы для работы с аудиофайлами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь для сохранения временного аудиофайла\n",
    "AUDIO_FOLDER = 'temp_audio'\n",
    "if not os.path.exists(AUDIO_FOLDER):\n",
    "    os.makedirs(AUDIO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data, language=\"ru-RU\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Не удалось распознать речь\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Ошибка запроса к сервису распознавания речи: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(input_file):\n",
    "    base_name, ext = os.path.splitext(input_file)\n",
    "    if ext != '.wav':\n",
    "        output_file = os.path.join(AUDIO_FOLDER, base_name + '.wav')\n",
    "        data, samplerate = sf.read(input_file)\n",
    "        sf.write(output_file, data, samplerate)\n",
    "        return output_file\n",
    "    else:\n",
    "        return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_path):\n",
    "    base_name, ext = os.path.splitext(audio_path)\n",
    "    output_path = base_name + '.wav'\n",
    "\n",
    "    # Загрузка аудиофайла с помощью librosa\n",
    "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Применение метода noisereduce для удаления шума\n",
    "    reduced_noise = nr.reduce_noise(y=audio_data, sr=sr)\n",
    "\n",
    "    # Сохранение очищенного аудиофайла\n",
    "    sf.write(output_path, reduced_noise, sr)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и запуск приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение пути для загрузки HTML-файла\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return send_file('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на наличие нарушения и вывод текста\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_audio():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'})\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'})\n",
    "    if file:\n",
    "        audio_file_path = convert_to_wav(file.filename)\n",
    "        denoised_audio_file_path = remove_noise(audio_file_path)\n",
    "        transcribed_text = transcribe_audio(denoised_audio_file_path)\n",
    "        new_text_vectorized = vectorizer.transform([transcribed_text])\n",
    "        prediction = model.predict(new_text_vectorized)\n",
    "        if prediction[0] == 1:\n",
    "            result = \"Нарушений не обнаружено: \" + new_text_vectorized.toarray().tolist() \n",
    "        else:\n",
    "            # Получаем список признаков и коэффициенты модели\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            coefs = model.coef_[0]\n",
    "\n",
    "            # Находим слова, которые имеют негативное влияние\n",
    "            negative_influence_words = [feature_names[i] for i in range(len(feature_names)) if new_text_vectorized[0, i] != 0 and coefs[i] < 0]\n",
    "\n",
    "            # Разделяем транскрибированный текст на слова\n",
    "            words = transcribed_text.split()\n",
    "\n",
    "            # Создаем новый список для выделенного текста\n",
    "            highlighted_words = []\n",
    "\n",
    "            # Проходимся по каждому слову в тексте\n",
    "            for word in words:\n",
    "                # Если слово является негативным, выделяем его звездочками\n",
    "                if word in negative_influence_words:\n",
    "                    highlighted_words.append(f\"*{word}*\")\n",
    "                else:\n",
    "                    highlighted_words.append(word)\n",
    "\n",
    "            # Объединяем слова обратно в строку\n",
    "            highlighted_text = ' '.join(highlighted_words)\n",
    "\n",
    "            result = \"Имеется нарушение: \" + highlighted_text\n",
    "        return jsonify({'result': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск сервера на локальном хосте\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
